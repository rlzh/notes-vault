{
  "main": {
    "id": "10a62eec088351f1",
    "type": "split",
    "children": [
      {
        "id": "fa67b64c69c40947",
        "type": "tabs",
        "children": [
          {
            "id": "6e648601da5c0219",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Paper Notes/2020 - Multi-agent Reinforcement Learning in Bayesian Stackelberg Markov Games for Adaptive Moving Target Defense - Sengupta.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "2020 - Multi-agent Reinforcement Learning in Bayesian Stackelberg Markov Games for Adaptive Moving Target Defense - Sengupta"
            }
          },
          {
            "id": "f57af9cb1541c014",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Paper Notes/2020 - Adaptive Cyber Defense Against Multi-Stage Attacks Using Learning-based  POMDP - Hu.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "2020 - Adaptive Cyber Defense Against Multi-Stage Attacks Using Learning-based  POMDP - Hu"
            }
          },
          {
            "id": "c5fb04d1081ddeb0",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "General Notes/Deep Reinforcement Learning.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Deep Reinforcement Learning"
            }
          },
          {
            "id": "99b43de7bafbf912",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "General Notes/Reinforcement Learning.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Reinforcement Learning"
            }
          },
          {
            "id": "878a336fb3c27093",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "General Notes/Markov Decision Process.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Markov Decision Process"
            }
          }
        ],
        "currentTab": 2
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "ea40044b7e4eaa48",
    "type": "split",
    "children": [
      {
        "id": "6819f57ce7c1c702",
        "type": "tabs",
        "children": [
          {
            "id": "658073136cf17116",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "179972238af25246",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "tag:#gametheory",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "48d2f359282c6fcb",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 281.500732421875
  },
  "right": {
    "id": "d2d5cadf429dda39",
    "type": "split",
    "children": [
      {
        "id": "a2868b2e6faea3bc",
        "type": "tabs",
        "children": [
          {
            "id": "f70035b59861810f",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Papers/Focus/2022-DecisionGTforSec-robust-MTD-against-unknown-attacks-meta-RL-approach-Li.pdf",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks for 2022-DecisionGTforSec-robust-MTD-against-unknown-attacks-meta-RL-approach-Li"
            }
          },
          {
            "id": "e2fad3a89049a6d7",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Papers/Focus/2022-DecisionGTforSec-robust-MTD-against-unknown-attacks-meta-RL-approach-Li.pdf",
                "linksCollapsed": true,
                "unlinkedCollapsed": false
              },
              "icon": "links-going-out",
              "title": "Outgoing links from 2022-DecisionGTforSec-robust-MTD-against-unknown-attacks-meta-RL-approach-Li"
            }
          },
          {
            "id": "74e71800e0989811",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "3d016d885bcc8c42",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "General Notes/Deep Reinforcement Learning.md"
              },
              "icon": "lucide-list",
              "title": "Outline of Deep Reinforcement Learning"
            }
          },
          {
            "id": "8db0d7f4d54f0067",
            "type": "leaf",
            "state": {
              "type": "all-properties",
              "state": {
                "sortOrder": "frequency",
                "showSearch": false,
                "searchQuery": ""
              },
              "icon": "lucide-archive",
              "title": "All properties"
            }
          }
        ],
        "currentTab": 3
      }
    ],
    "direction": "horizontal",
    "width": 200,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "obsidian-excalidraw-plugin:Create new drawing": false
    }
  },
  "active": "c5fb04d1081ddeb0",
  "lastOpenFiles": [
    "General Notes/Statistics.md",
    "General Notes/Information Theory.md",
    "General Notes/Deep Reinforcement Learning.md",
    "Pasted image 20241213005547.png",
    "General Notes/Reinforcement Learning.md",
    "Reference Images/reinforce-algo-variance-vis.png",
    "General Notes/Deep Learning.md",
    "General Notes/Problem Complexity.md",
    "General Notes/Machine Learning.md",
    "Reference Images/gradient-descent-visual.png",
    "General Notes/Calculus.md",
    "Paper Notes/2020 - Adaptive Cyber Defense Against Multi-Stage Attacks Using Learning-based  POMDP - Hu.md",
    "Reference Images/value-iteration-algo.png",
    "Reference Images/gradient-descent.png",
    "2024-12-12.md",
    "Untitled.canvas",
    "Reference Images/TD-update-step.png",
    "Reference Images/stable-deep-q-learning-algo.png",
    "Reference Images/q-learning-algo.png",
    "Templates/Paper Review Template.md",
    "README.md",
    "Paper Drafts/SEAMS 2025.md",
    "General Notes/Stackelberg Game.md",
    "General Notes/Bayes' Theorem.md",
    "General Notes/CVSS.md",
    "General Notes/Linear Programming.md",
    "General Notes/Laplace Transform.md",
    "General Notes/Foundational Logic and Reasoning.md",
    "General Notes/Cyber Security.md",
    "Reference Images/obj-function-policy-gradient.png",
    "Reference Images/TD-target-calc.png",
    "Paper Notes/2017 - A Game Theoretic Approach to Strategy Generation for Moving Target Defense in Web Applications - Sengupta.md",
    "2012-NIPS-efficient-bayes-adaptive-reinforcement-learning-using-sample-based-search-Guez.pdf.md",
    "Untitled 1.md",
    "General Notes/Markov Decision Process.md",
    "Papers/Focus/2018-arxiv-first-order-meta-learning-algo-Nichol.pdf",
    "Paper Notes/2018 - On First-Order Meta-Learning Algorithms - Nichol.md",
    "Paper Notes/2012 - Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search - Guez.md",
    "Papers/Focus/2022-DecisionGTforSec-robust-MTD-against-unknown-attacks-meta-RL-approach-Li.pdf",
    "Papers/Focus/2023-arxiv-reptile-algorithm-RL-for-mario-Jain.pdf",
    "Papers/Focus/2020-arxiv-mult-agent-RL-in-bayesian-stackelberg-markov-games-for-MTD-Sengupta.pdf",
    "Papers/Focus/2012-NIPS-efficient-bayes-adaptive-reinforcement-learning-using-sample-based-search-Guez.pdf",
    "Papers/Focus/2020-TransPrivSec-adaptive-defense-multi-stage-attack-using-POMDP-Hu.pdf",
    "Papers/Focus/2017-AAMAS-GT-approach-to-strat-gen-for-MTD-in-web-apps-Sengupta.pdf",
    "Papers/Focus/2022-arxiv-deep-interactive-bayesian-RL-via-meta-learning-Zintgraf.pdf",
    "Papers/Filtered/security/2002-CSFW-two-formal-analyses-of-attack-graphs-Jha.pdf",
    "Papers/Filtered/sas/2023-SEAMS-distrib-MAPEK-for-self-protect-IoT-devices-Riegler.pdf"
  ]
}